{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/aeiwz/Library/CloudStorage/OneDrive-KhonKaenUniversity/KKUPC/Project/Alpha/KKUPC6602013/Re-analyse/Raw data/Dataset/KKUPC6602013_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop QC\n",
    "df = df2.drop(df2[df2['Group'] == 'QC'].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = df.iloc[:, 43:]\n",
    "ppm = spectra.columns.values.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Preprocessing data set to decrease noise\n",
    "def decrease_noise(spectra, window_length=11, polyorder=2):\n",
    "    import numpy as np\n",
    "    from scipy.signal import savgol_filter\n",
    "    \"\"\"\n",
    "    Decrease the noise of spectra using Savitzky-Golay filter.\n",
    "    \n",
    "    Parameters:\n",
    "    - spectra: numpy array or pandas DataFrame\n",
    "        The spectra data to be processed.\n",
    "    - window_length: int, optional (default=11)\n",
    "        The length of the window used for filtering.\n",
    "    - polyorder: int, optional (default=2)\n",
    "        The order of the polynomial used for fitting.\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_spectra: numpy array or pandas DataFrame\n",
    "        The spectra data after noise reduction.\n",
    "    \"\"\"\n",
    "    if isinstance(spectra, np.ndarray):\n",
    "        filtered_spectra = savgol_filter(spectra, window_length, polyorder, axis=1)\n",
    "    elif isinstance(spectra, pd.DataFrame):\n",
    "        filtered_spectra = spectra.apply(lambda x: savgol_filter(x, window_length, polyorder))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid data type. Expected numpy array or pandas DataFrame.\")\n",
    "    \n",
    "    return filtered_spectra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_denoise = decrease_noise(spectra, window_length=11, polyorder=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_spec = pd.DataFrame()\n",
    "for i in range(len(df['Intervention'].unique())):\n",
    "    index_ = df[df['Intervention'] == df['Intervention'].unique()[i]].index\n",
    "    spec_ = spec_denoise.iloc[index_, :]\n",
    "    mean_spec = spec_.mean(axis=0)\n",
    "    spec_ = np.absolute(spec_ - mean_spec)\n",
    "    #spec_ = decrease_noise(spec_, window_length=4, polyorder=2)\n",
    "    sub_spec = pd.concat([sub_spec, spec_], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(spectra)):\n",
    "    plt.plot(ppm, spec_denoise.iloc[i, :])\n",
    "\n",
    "\n",
    "#invert x-axis\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel('ppm')\n",
    "plt.ylabel('Intensity')\n",
    "plt.title('Spectra of each sample')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(spectra)):\n",
    "    plt.plot(ppm, sub_spec.iloc[i, :])\n",
    "\n",
    "\n",
    "#invert x-axis\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel('ppm')\n",
    "plt.ylabel('Intensity')\n",
    "plt.title('Spectra of each sample')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the required python packages including \n",
    "# the custom Chemometric Model objects\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyChemometrics.ChemometricsPCA import ChemometricsPCA\n",
    "from pyChemometrics.ChemometricsScaler import ChemometricsScaler\n",
    "\n",
    "# Use to obtain same values as in the text\n",
    "np.random.seed(350)\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import scale\n",
    "from pca_ellipse import confidence_ellipse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fill nan with 0\n",
    "X = sub_spec\n",
    "Y = df['Intervention']\n",
    "Y1 = pd.Categorical(Y).codes\n",
    "ppm = list(np.ravel(X.columns).astype(float))\n",
    "# Use pandas Categorical type to generate the dummy enconding of the Y vector (0 and 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale__ = 'UV'\n",
    "scale_power_ = 1\n",
    "\n",
    "\n",
    "model_scaler = ChemometricsScaler(scale_power=scale_power_)\n",
    "model_scaler.fit(X)\n",
    "model_X = model_scaler.transform(X)\n",
    "\n",
    "pca_model = decomposition.PCA(n_components=2)\n",
    "pca_model.fit(model_X)\n",
    "\n",
    "scores_ = pca_model.transform(model_X)\n",
    "df_scores_ = pd.DataFrame(scores_, columns=['PC1', 'PC2'])\n",
    "#df_scores_.index = X.index\n",
    "\n",
    "df2_scores_ = pd.concat([df_scores_, Y], axis=1)\n",
    "\n",
    "#save PCA score to csv\n",
    "#df2_scores_.to_csv('{}/PCA_scores_{}.csv'.format(Scores_save, name[i]))\n",
    "\n",
    "loadings_ = pca_model.components_.T\n",
    "df_loadings_ = pd.DataFrame(loadings_, columns=['PC1', 'PC2'], index=np.ravel(ppm))\n",
    "#df_loadings_.to_csv(Loading_save + '/Loading_scores ' + plot_name + '.csv')\n",
    "\n",
    "explained_variance_ = pca_model.explained_variance_ratio_\n",
    "explained_variance_\n",
    "\n",
    "explained_variance_ = np.insert(explained_variance_, 0, 0)\n",
    "\n",
    "cumulative_variance_ = np.cumsum(np.round(explained_variance_, decimals=3))\n",
    "\n",
    "pc_df_ = pd.DataFrame(['','PC1', 'PC2'], columns=['PC'])\n",
    "explained_variance_df_ = pd.DataFrame(explained_variance_, columns=['Explained Variance'])\n",
    "cumulative_variance_df_ = pd.DataFrame(cumulative_variance_, columns=['Cumulative Variance'])\n",
    "\n",
    "df_explained_variance_ = pd.concat([pc_df_, explained_variance_df_, cumulative_variance_df_], axis=1)\n",
    "#df_explained_variance_.to_csv(R2_save + '/R2 ' + plot_name + '.csv')\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=357)\n",
    "X_test = model_scaler.transform(X_test)\n",
    "X_test_pca = pca_model.transform(X_test)\n",
    "\n",
    "# Inverse transform the test set from the PCA space\n",
    "X_test_reconstructed = pca_model.inverse_transform(X_test_pca)\n",
    "\n",
    "\n",
    "# Calculate Q2 score for the test set\n",
    "q2_test = r2_score(X_test, X_test_reconstructed)\n",
    "\n",
    "\n",
    "# PCA plot\n",
    "pca_label = df2_scores_.index\n",
    "\n",
    "\n",
    "fig = px.scatter(df2_scores_, x='PC1', y='PC2',\n",
    "                color='Intervention',\n",
    "                color_discrete_map={\n",
    "                                    \"UCMS\": \"#E91E63\",        \n",
    "                                    \"TKM powder 150 mg/kg\": \"#FF9800\",\n",
    "                                    \"Imipramine\": \"#FFEB3B\",       \n",
    "                                    \"TKM powder 37.5 mg/kg\": \"#9C27B0\",\n",
    "                                    \"Vitamin E\": \"#03A9F4\",\n",
    "                                    \"Diazepam\": \"#4CAF50\",        \n",
    "                                    \"TKM powder 600 mg/kg\": \"#B30000\",\n",
    "                                    \"0.5% SCMC\": \"#3F51B5\"\n",
    "                                    }, \n",
    "                title='<b>PCA Scores Plot ({} Scaling)<b>'.format(scale__), \n",
    "                height=900, width=1300,\n",
    "                labels={\"PC1\": \"PC1 R<sup>2</sup>X: {} %\".format(np.round(df_explained_variance_.iloc[1,1]*100, decimals=2)),\n",
    "                        \"PC2\": \"PC2 R<sup>2</sup>X: {} %\".format(np.round(df_explained_variance_.iloc[2,1]*100, decimals=2))},\n",
    "                text=df.index)\n",
    "\n",
    "#fig.add_annotation(yref = 'paper', y = -1.06, xref = 'paper', x=1.06 , text='Q2' +' = {}'.format(np.round(df_explained_variance_.iloc[2,2], decimals=2)))\n",
    "#fig.update_annotations(font = {\n",
    "#    'size': 20}, showarrow=False)\n",
    "\n",
    "#set data point fill alpha with boarder in each color\n",
    "fig.update_traces(marker=dict(size=35, opacity=0.7, line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=20),\n",
    "                        #x=x_loc,\n",
    "                        x=1.0,\n",
    "                        y=0.05,\n",
    "                        showarrow=False,\n",
    "                        text='<b>R<sup>2</sup>X (Cum): {}%<b>'.format(np.round(df_explained_variance_.iloc[2,2]*100, decimals=2)),\n",
    "                        textangle=0,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"),\n",
    "                        # set alignment of text to left side of entry\n",
    "                        align=\"left\")\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=20),\n",
    "                          #x=x_loc,\n",
    "                        x=1.0,\n",
    "                        y=0.01,\n",
    "                        showarrow=False,\n",
    "                        text='<b>Q<sup>2</sup>X (Cum): {}%<b>'.format(np.round(q2_test*100, decimals=2)),\n",
    "                        textangle=0,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"),\n",
    "                        # set alignment of text to left side of entry\n",
    "                        align=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "fig.update_traces(marker=dict(size=35))\n",
    "#fig.update_traces(textposition='top center') #Text label position\n",
    "\n",
    "#fig.update_traces(marker=dict(size=12, color=Y1_color, marker=Y2_marker))\n",
    "fig.add_shape(type='path',\n",
    "            path=confidence_ellipse(df2_scores_['PC1'], df2_scores_['PC2']))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_xaxes(zeroline=True, zerolinewidth=2, zerolinecolor='Black')\n",
    "fig.update_yaxes(zeroline=True, zerolinewidth=2, zerolinecolor='Black')\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black')\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black')\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'y':1,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    font=dict(size=20))\n",
    "fig.update_layout(paper_bgcolor='rgba(0,0,0,0)',plot_bgcolor='rgba(0,0,0,0)')\n",
    "\n",
    "#fig.show()\n",
    "#fig.write_image(PNG_save + \"/PCA \" + plot_name + \".png\")\n",
    "#fig.write_html(HTML_save + \"/PCA \" + plot_name + \".html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fill nan with 0\n",
    "X = spec_denoise\n",
    "Y = df['Intervention']\n",
    "Y1 = pd.Categorical(Y).codes\n",
    "ppm = list(np.ravel(X.columns).astype(float))\n",
    "# Use pandas Categorical type to generate the dummy enconding of the Y vector (0 and 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale__ = 'UV'\n",
    "scale_power_ = 1\n",
    "\n",
    "# Mean Centering (MC):\n",
    "#scaling_object_mc = ChemometricsScaler(scale_power=0)\n",
    "\n",
    "# Pareto scaling (Par):\n",
    "# scaling_object_par = ChemometricsScaler(scale_power=0.5)\n",
    "\n",
    "\n",
    "model_scaler = ChemometricsScaler(scale_power=scale_power_)\n",
    "model_scaler.fit(X)\n",
    "model_X = model_scaler.transform(X)\n",
    "\n",
    "pca_model = decomposition.PCA(n_components=2)\n",
    "pca_model.fit(model_X)\n",
    "\n",
    "scores_ = pca_model.transform(model_X)\n",
    "df_scores_ = pd.DataFrame(scores_, columns=['PC1', 'PC2'])\n",
    "#df_scores_.index = X.index\n",
    "\n",
    "df2_scores_ = pd.concat([df_scores_, Y], axis=1)\n",
    "\n",
    "#save PCA score to csv\n",
    "#df2_scores_.to_csv('{}/PCA_scores_{}.csv'.format(Scores_save, name[i]))\n",
    "\n",
    "loadings_ = pca_model.components_.T\n",
    "df_loadings_ = pd.DataFrame(loadings_, columns=['PC1', 'PC2'], index=np.ravel(ppm))\n",
    "#df_loadings_.to_csv(Loading_save + '/Loading_scores ' + plot_name + '.csv')\n",
    "\n",
    "explained_variance_ = pca_model.explained_variance_ratio_\n",
    "explained_variance_\n",
    "\n",
    "explained_variance_ = np.insert(explained_variance_, 0, 0)\n",
    "\n",
    "cumulative_variance_ = np.cumsum(np.round(explained_variance_, decimals=3))\n",
    "\n",
    "pc_df_ = pd.DataFrame(['','PC1', 'PC2'], columns=['PC'])\n",
    "explained_variance_df_ = pd.DataFrame(explained_variance_, columns=['Explained Variance'])\n",
    "cumulative_variance_df_ = pd.DataFrame(cumulative_variance_, columns=['Cumulative Variance'])\n",
    "\n",
    "df_explained_variance_ = pd.concat([pc_df_, explained_variance_df_, cumulative_variance_df_], axis=1)\n",
    "#df_explained_variance_.to_csv(R2_save + '/R2 ' + plot_name + '.csv')\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=357)\n",
    "X_test = model_scaler.transform(X_test)\n",
    "X_test_pca = pca_model.transform(X_test)\n",
    "\n",
    "# Inverse transform the test set from the PCA space\n",
    "X_test_reconstructed = pca_model.inverse_transform(X_test_pca)\n",
    "\n",
    "\n",
    "# Calculate Q2 score for the test set\n",
    "q2_test = r2_score(X_test, X_test_reconstructed)\n",
    "\n",
    "\n",
    "# PCA plot\n",
    "pca_label = df2_scores_.index\n",
    "\n",
    "\n",
    "fig = px.scatter(df2_scores_, x='PC1', y='PC2',\n",
    "                color='Intervention',\n",
    "                color_discrete_map={\n",
    "                                    \"UCMS\": \"#E91E63\",        \n",
    "                                    \"TKM powder 150 mg/kg\": \"#FF9800\",\n",
    "                                    \"Imipramine\": \"#FFEB3B\",       \n",
    "                                    \"TKM powder 37.5 mg/kg\": \"#9C27B0\",\n",
    "                                    \"Vitamin E\": \"#03A9F4\",\n",
    "                                    \"Diazepam\": \"#4CAF50\",        \n",
    "                                    \"TKM powder 600 mg/kg\": \"#B30000\",\n",
    "                                    \"0.5% SCMC\": \"#3F51B5\"\n",
    "                                    }, \n",
    "                title='<b>PCA Scores Plot ({} Scaling)<b>'.format(scale__), \n",
    "                height=900, width=1300,\n",
    "                labels={\"PC1\": \"PC1 R<sup>2</sup>X: {} %\".format(np.round(df_explained_variance_.iloc[1,1]*100, decimals=2)),\n",
    "                        \"PC2\": \"PC2 R<sup>2</sup>X: {} %\".format(np.round(df_explained_variance_.iloc[2,1]*100, decimals=2))},\n",
    "                text=df['Cage'])\n",
    "\n",
    "#fig.add_annotation(yref = 'paper', y = -1.06, xref = 'paper', x=1.06 , text='Q2' +' = {}'.format(np.round(df_explained_variance_.iloc[2,2], decimals=2)))\n",
    "#fig.update_annotations(font = {\n",
    "#    'size': 20}, showarrow=False)\n",
    "\n",
    "#set data point fill alpha with boarder in each color\n",
    "fig.update_traces(marker=dict(size=35, opacity=0.7, line=dict(width=2, color='DarkSlateGrey')))\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=20),\n",
    "                        #x=x_loc,\n",
    "                        x=1.0,\n",
    "                        y=0.05,\n",
    "                        showarrow=False,\n",
    "                        text='<b>R<sup>2</sup>X (Cum): {}%<b>'.format(np.round(df_explained_variance_.iloc[2,2]*100, decimals=2)),\n",
    "                        textangle=0,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"),\n",
    "                        # set alignment of text to left side of entry\n",
    "                        align=\"left\")\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=20),\n",
    "                          #x=x_loc,\n",
    "                        x=1.0,\n",
    "                        y=0.01,\n",
    "                        showarrow=False,\n",
    "                        text='<b>Q<sup>2</sup>X (Cum): {}%<b>'.format(np.round(q2_test*100, decimals=2)),\n",
    "                        textangle=0,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"),\n",
    "                        # set alignment of text to left side of entry\n",
    "                        align=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "fig.update_traces(marker=dict(size=35))\n",
    "#fig.update_traces(textposition='top center') #Text label position\n",
    "\n",
    "#fig.update_traces(marker=dict(size=12, color=Y1_color, marker=Y2_marker))\n",
    "fig.add_shape(type='path',\n",
    "            path=confidence_ellipse(df2_scores_['PC1'], df2_scores_['PC2']))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_xaxes(zeroline=True, zerolinewidth=2, zerolinecolor='Black')\n",
    "fig.update_yaxes(zeroline=True, zerolinewidth=2, zerolinecolor='Black')\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor='black')\n",
    "fig.update_yaxes(showline=True, linewidth=2, linecolor='black')\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'y':1,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    font=dict(size=20))\n",
    "fig.update_layout(paper_bgcolor='rgba(0,0,0,0)',plot_bgcolor='rgba(0,0,0,0)')\n",
    "\n",
    "#fig.show()\n",
    "#fig.write_image(PNG_save + \"/PCA \" + plot_name + \".png\")\n",
    "#fig.write_html(HTML_save + \"/PCA \" + plot_name + \".html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/js/gsdvs9d11jd4g5m9s3xj33c80000gn/T/ipykernel_74258/491393022.py:1: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv('/Users/aeiwz/Library/CloudStorage/OneDrive-KhonKaenUniversity/KKUPC/Project/Alpha/KKUPC6602013/Re-analyse/Raw data/Dataset/KKUPC6602013_dataset.csv')\n",
      "/var/folders/js/gsdvs9d11jd4g5m9s3xj33c80000gn/T/ipykernel_74258/491393022.py:2: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv('/Users/aeiwz/Library/CloudStorage/OneDrive-KhonKaenUniversity/KKUPC/Project/Alpha/KKUPC6602014/Dataset/KKUPC6602014_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('/Users/aeiwz/Library/CloudStorage/OneDrive-KhonKaenUniversity/KKUPC/Project/Alpha/KKUPC6602013/Re-analyse/Raw data/Dataset/KKUPC6602013_dataset.csv')\n",
    "df2 = pd.read_csv('/Users/aeiwz/Library/CloudStorage/OneDrive-KhonKaenUniversity/KKUPC/Project/Alpha/KKUPC6602014/Dataset/KKUPC6602014_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1\n",
    "spectra = df.iloc[:, 28:]\n",
    "ppm = spectra.columns.values.astype(float)\n",
    "metadata = df.iloc[:, :28]\n",
    "feature_ = df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(spectra, feature_name, metadata, window_length=11, polyorder=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Preprocessing data set to decrease noise and normalize.\n",
    "\n",
    "    Parameters:\n",
    "    - spectra: numpy array or pandas DataFrame\n",
    "        The spectra data to be processed.\n",
    "    - feature_name: list\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    from denoise_spec import Denoise\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    spectra = Denoise.decrease_noise(spectra, window_length=window_length, polyorder=polyorder)\n",
    "    spectra = pd.DataFrame(spectra)\n",
    "    spectra.columns = feature_name\n",
    "    combind = pd.concat([metadata, spectra], axis=1, ignore_index=True)\n",
    "\n",
    "    return combind\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing_data(spectra, ppm, metadata, window_length=17, polyorder=3)\n",
    "data.columns = feature_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('/Users/aeiwz/Library/CloudStorage/OneDrive-KhonKaenUniversity/KKUPC/Project/Alpha/KKUPC6602013/Re-analyse/Raw data/Dataset/KKUPC6602013_dataset_preprocessed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
